{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/albumentations-team/albumentations\n",
      "  Cloning https://github.com/albumentations-team/albumentations to c:\\users\\feers\\appdata\\local\\temp\\pip-req-build-31hid_s2\n",
      "  Resolved https://github.com/albumentations-team/albumentations to commit 3e09e4bab7f582c7dce3473826558826f4d5df0e\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\feers\\anaconda3\\envs\\bacteri\\lib\\site-packages (from albumentations==1.4.21) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\feers\\anaconda3\\envs\\bacteri\\lib\\site-packages (from albumentations==1.4.21) (1.13.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\feers\\anaconda3\\envs\\bacteri\\lib\\site-packages (from albumentations==1.4.21) (6.0.2)\n",
      "Collecting pydantic>=2.7.0 (from albumentations==1.4.21)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting albucore==0.0.21 (from albumentations==1.4.21)\n",
      "  Using cached albucore-0.0.21-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting eval-type-backport (from albumentations==1.4.21)\n",
      "  Using cached eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations==1.4.21)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\feers\\anaconda3\\envs\\bacteri\\lib\\site-packages (from albumentations==1.4.21) (4.11.0)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in c:\\users\\feers\\anaconda3\\envs\\bacteri\\lib\\site-packages (from albucore==0.0.21->albumentations==1.4.21) (3.10.10)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in c:\\users\\feers\\anaconda3\\envs\\bacteri\\lib\\site-packages (from albucore==0.0.21->albumentations==1.4.21) (6.0.5)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.0->albumentations==1.4.21)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\feers\\anaconda3\\envs\\bacteri\\lib\\site-packages (from pydantic>=2.7.0->albumentations==1.4.21) (2.23.4)\n",
      "Using cached albucore-0.0.21-py3-none-any.whl (12 kB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Using cached eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Building wheels for collected packages: albumentations\n",
      "  Building wheel for albumentations (pyproject.toml): started\n",
      "  Building wheel for albumentations (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for albumentations: filename=albumentations-1.4.21-py3-none-any.whl size=244575 sha256=5a57622f1c7166dd34e9d77e17154810fac3a6ca3ee9f42d45d2394a62279a15\n",
      "  Stored in directory: C:\\Users\\feers\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-2sqgv_4c\\wheels\\6d\\72\\93\\d30af2a1f90e7c7e811e8fa43aa723971c91af45052ffa1b5a\n",
      "Successfully built albumentations\n",
      "Installing collected packages: opencv-python-headless, eval-type-backport, annotated-types, pydantic, albucore, albumentations\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/albumentations-team/albumentations 'C:\\Users\\feers\\AppData\\Local\\Temp\\pip-req-build-31hid_s2'\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\Users\\\\feers\\\\anaconda3\\\\envs\\\\bacteri\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Using cached scikit_image-0.24.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\feers\\anaconda3\\envs\\bacteri\\lib\\site-packages (from scikit-image) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\feers\\anaconda3\\envs\\bacteri\\lib\\site-packages (from scikit-image) (1.13.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\feers\\anaconda3\\envs\\bacteri\\lib\\site-packages (from scikit-image) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\feers\\anaconda3\\envs\\bacteri\\lib\\site-packages (from scikit-image) (10.4.0)\n",
      "Collecting imageio>=2.33 (from scikit-image)\n",
      "  Using cached imageio-2.36.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Using cached tifffile-2024.8.30-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\feers\\anaconda3\\envs\\bacteri\\lib\\site-packages (from scikit-image) (24.1)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Using cached scikit_image-0.24.0-cp39-cp39-win_amd64.whl (12.9 MB)\n",
      "Using cached imageio-2.36.0-py3-none-any.whl (315 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached tifffile-2024.8.30-py3-none-any.whl (227 kB)\n",
      "Installing collected packages: tifffile, lazy-loader, imageio, scikit-image\n",
      "Successfully installed imageio-2.36.0 lazy-loader-0.4 scikit-image-0.24.0 tifffile-2024.8.30\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U git+https://github.com/albumentations-team/albumentations\n",
    "\n",
    "%pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from skimage.io import imread\n",
    "from threading import Lock\n",
    "\n",
    "# Path ke folder data\n",
    "images_dir = \"D:\\KULIAH\\SEMESTER 5\\RSBP\\Bacteri\\Detection-of-bacteria-in-water-using-Yolo-images\\Detect\\Detection-of-bacteria-in-water-using-Yolo-images\\EMDS7\"\n",
    "labels_dir = \"D:\\KULIAH\\SEMESTER 5\\RSBP\\Bacteri\\Detection-of-bacteria-in-water-using-Yolo-images\\Detect\\Detection-of-bacteria-in-water-using-Yolo-images\\EMDS7xml\"\n",
    "output_dir = \"D:\\KULIAH\\SEMESTER 5\\RSBP\\Bacteri\\Detection-of-bacteria-in-water-using-Yolo-images\\Detect\\Detection-of-bacteria-in-water-using-Yolo-images\\\\temp\"\n",
    "sample_output_dir = \"D:\\KULIAH\\SEMESTER 5\\RSBP\\Bacteri\\Detection-of-bacteria-in-water-using-Yolo-images\\Detect\\Detection-of-bacteria-in-water-using-Yolo-images\\sample_output\"\n",
    "\n",
    "train_val_split = 0.8  # Rasio data train/validation\n",
    "\n",
    "# Cek apakah path gambar dan label ada\n",
    "if not os.path.exists(images_dir):\n",
    "    raise FileNotFoundError(f\"Path gambar tidak ditemukan: {images_dir}\")\n",
    "if not os.path.exists(labels_dir):\n",
    "    raise FileNotFoundError(f\"Path label tidak ditemukan: {labels_dir}\")\n",
    "\n",
    "# Remove output directory if it exists and create fresh output folders\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "if os.path.exists(sample_output_dir):\n",
    "    shutil.rmtree(sample_output_dir)\n",
    "\n",
    "# Buat ulang folder output yang fresh\n",
    "os.makedirs(os.path.join(output_dir, 'images/train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'images/val'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'labels/train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'labels/val'), exist_ok=True)\n",
    "os.makedirs(sample_output_dir, exist_ok=True)\n",
    "\n",
    "# Daftar semua gambar dan annotations\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith('.png')]\n",
    "label_files = [f.replace('.png', '.xml') for f in image_files]\n",
    "\n",
    "# Shuffle data for randomness\n",
    "data = list(zip(image_files, label_files))\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "split_index = int(train_val_split * len(data))\n",
    "train_data = data[:split_index]\n",
    "val_data = data[split_index:]\n",
    "\n",
    "class_mapping = {\n",
    "    'G001': 0, 'G002': 1, 'G003': 2, 'G004': 3, 'G005': 4, 'G006': 5, 'G007': 6, 'G008': 7, 'G009': 8, 'G010': 9,\n",
    "    'G011': 10, 'G012': 11, 'G013': 12, 'G014': 13, 'G015': 14, 'G016': 15, 'G017': 16, 'G018': 17, 'G019': 18, 'G020': 19,\n",
    "    'G021': 20, 'G022': 21, 'G023': 22, 'G024': 23, 'G025': 24, 'G026': 25, 'G027': 26, 'G028': 27, 'G029': 28, 'G030': 29,\n",
    "    'G031': 30, 'G032': 31, 'G033': 32, 'G034': 33, 'G035': 34, 'G036': 35, 'G037': 36, 'G038': 37, 'G039': 38, 'G040': 39,\n",
    "    'G041': 40, 'G042': 41, 'G043': 42, 'G044': 43, 'G045': 44, 'G046': 45, 'G047': 46, 'G048': 47, 'G049': 48, 'G050': 49,\n",
    "    'G051': 50, 'G052': 51, 'G053': 52\n",
    "}\n",
    "\n",
    "# Augmentasi gambar dan bounding box tanpa mirroring, mengisi area kosong dengan putih\n",
    "augmentor = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.3),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Resize(512, 512, p=1.0)\n",
    "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "sample_counter_lock = Lock()\n",
    "\n",
    "def draw_bboxes(image, bboxes, class_labels):\n",
    "    \"\"\"Gambar bounding box pada gambar.\"\"\"\n",
    "    for bbox, class_id in zip(bboxes, class_labels):\n",
    "        x_center, y_center, width, height = bbox\n",
    "        img_h, img_w = image.shape[:2]\n",
    "        xmin = int((x_center - width / 2) * img_w)\n",
    "        ymin = int((y_center - height / 2) * img_h)\n",
    "        xmax = int((x_center + width / 2) * img_w)\n",
    "        ymax = int((y_center + height / 2) * img_h)\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "        cv2.putText(image, str(class_id), (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "def convert_xml_to_txt(xml_path, txt_output_path, augment=False, img=None):\n",
    "    \"\"\"Fungsi ini akan mengonversi format XML ke format YOLO (txt).\"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    width = int(root.find('size/width').text)\n",
    "    height = int(root.find('size/height').text)\n",
    "    bboxes = []\n",
    "    class_labels = []\n",
    "\n",
    "    for obj in root.findall('object'):\n",
    "        class_name = obj.find('name').text\n",
    "        class_id = class_mapping.get(class_name, -1)\n",
    "        if class_id == -1:\n",
    "            continue\n",
    "        bndbox = obj.find('bndbox')\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "        x_center = (xmin + xmax) / 2.0 / width\n",
    "        y_center = (ymin + ymax) / 2.0 / height\n",
    "        box_width = (xmax - xmin) / width\n",
    "        box_height = (ymax - ymin) / height\n",
    "        bboxes.append([x_center, y_center, box_width, box_height])\n",
    "        class_labels.append(class_id)\n",
    "\n",
    "    with open(txt_output_path, 'w') as txt_file:\n",
    "        for bbox, label in zip(bboxes, class_labels):\n",
    "            txt_file.write(f\"{label} {' '.join(map(str, bbox))}\\n\")\n",
    "\n",
    "    return img, bboxes, class_labels\n",
    "\n",
    "def apply_morphology(img, kernel_size=(10, 10), blur_kernel=(5, 5)):\n",
    "    \"\"\"Terapkan operasi thresholding dengan Gaussian blur, median blur, top-hat, dan adaptive thresholding.\"\"\"\n",
    "    # Jika gambar berwarna, konversi ke grayscale\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "    \n",
    "    # Tambahkan Gaussian blur untuk mengurangi noise awal\n",
    "    blurred = cv2.GaussianBlur(gray, blur_kernel, 0)\n",
    "    \n",
    "    # Membuat elemen struktural berbentuk disk kecil untuk top-hat\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_size)\n",
    "    \n",
    "    # Top-hat untuk menonjolkan detail bakteri\n",
    "    tophat_img = cv2.morphologyEx(blurred, cv2.MORPH_TOPHAT, kernel)\n",
    "    \n",
    "    # Tambahkan Median Blur pada hasil top-hat untuk mengurangi noise\n",
    "    tophat_blur = cv2.medianBlur(tophat_img, 5)\n",
    "    \n",
    "    # Bilateral Filter untuk menghaluskan area dalam tanpa menghilangkan tepi\n",
    "    tophat_bilateral = cv2.bilateralFilter(tophat_blur, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    \n",
    "    # Adaptive thresholding setelah top-hat dan blur\n",
    "    bwnewimg = cv2.adaptiveThreshold(tophat_bilateral, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                     cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    return bwnewimg\n",
    "\n",
    "def process_data(img_file, lbl_file, img_dest_folder, lbl_dest_folder, augment=False, sample_output_count=15):\n",
    "    img_src_path = os.path.join(images_dir, img_file)\n",
    "    lbl_src_path = os.path.join(labels_dir, lbl_file)\n",
    "\n",
    "    # Baca gambar dan konversi ke grayscale\n",
    "    img = imread(img_src_path)\n",
    "    img = apply_morphology(img)\n",
    "    \n",
    "    if augment:\n",
    "        img_dest_path = os.path.join(img_dest_folder, img_file.replace('.png', '_aug.png'))\n",
    "        lbl_dest_path = os.path.join(lbl_dest_folder, lbl_file.replace('.xml', '_aug.txt'))\n",
    "        augmented_img, augmented_bboxes, class_labels = convert_xml_to_txt(lbl_src_path, lbl_dest_path, augment=True, img=img)\n",
    "\n",
    "        augmented = augmentor(image=augmented_img, bboxes=augmented_bboxes, class_labels=class_labels)\n",
    "        augmented_img = augmented['image']\n",
    "        augmented_bboxes = augmented['bboxes']\n",
    "\n",
    "        # Draw bounding boxes on augmented image and save to sample output\n",
    "        with sample_counter_lock:\n",
    "            if sample_output_count > 0:\n",
    "                sample_img = augmented_img.copy()\n",
    "                draw_bboxes(sample_img, augmented_bboxes, class_labels)\n",
    "                cv2.imwrite(os.path.join(sample_output_dir, f\"{img_file.replace('.png', '_aug_sample.png')}\") , sample_img)\n",
    "                sample_output_count -= 1\n",
    "\n",
    "        # Save the augmented image in the train directory\n",
    "        cv2.imwrite(img_dest_path, augmented_img)\n",
    "        print(f\"Augmented Image saved to: {img_dest_path}\")\n",
    "    else:\n",
    "        img_dest_path = os.path.join(img_dest_folder, img_file)\n",
    "        lbl_dest_path = os.path.join(lbl_dest_folder, lbl_file.replace('.xml', '.txt'))\n",
    "        shutil.copy(img_src_path, img_dest_path)\n",
    "        convert_xml_to_txt(lbl_src_path, lbl_dest_path)\n",
    "        print(f\"Original Image saved to: {img_dest_path}\")\n",
    "\n",
    "def copy_and_convert_data(data, img_dest_folder, lbl_dest_folder, augment=False, sample_output_count=30):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for img_file, lbl_file in data:\n",
    "            futures.append(executor.submit(process_data, img_file, lbl_file, img_dest_folder, lbl_dest_folder, augment, sample_output_count))\n",
    "        for future in as_completed(futures):\n",
    "            future.result()\n",
    "\n",
    "copy_and_convert_data(train_data, os.path.join(output_dir, 'images/train'), os.path.join(output_dir, 'labels/train'), augment=True)\n",
    "copy_and_convert_data(val_data, os.path.join(output_dir, 'images/val'), os.path.join(output_dir, 'labels/val'))\n",
    "\n",
    "print(\"Data berhasil dipisah, dikonversi, dan diaugmentasi ke format YOLO! Contoh gambar disimpan di folder sample_output.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bacteri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
